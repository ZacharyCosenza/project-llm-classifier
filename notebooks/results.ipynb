{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb688cf",
   "metadata": {},
   "source": [
    "# run_1_distilBERT.ipynb\n",
    "\n",
    "For this run I trained a small NN head on top of a distilBERT LLM with hidden size 768, layers 6, heads 12. The model is very simple: text is tokenized using distilbert-base-uncased with max length 512, passed to LLM where I take the last layer output (size 768) for A and B, concatenate them, then pass them into the head. This produces logits which are classified A/B/Tie. For batch size 32, 3 epochs with AdamW and lr of 1e-5 resulted in accuracy no better than chance (~33%). Afte this initial experiment, the next logic step is to inject information about the prompt into the training. The most challenging aspect was getting Intel's XPUs to play nice on a Windows 11 machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea9f79b",
   "metadata": {},
   "source": [
    "# run_2_appendprompt.ipynb\n",
    "\n",
    "For this run I used the previous run 1 results but appended the tokenized prompt to the beginning of the responses. This increased the compute needs which required me to move to a batch size of 2 and single epoch to conserve memory on my machine and reduce the time of the experiment. The accuracy of the test set was ~45%, which was a considerable improvement over run 1. However, it is unclear if that is due to changing batch size or the prompt appending. Now that we have a direction, the next step is to improve the compute situation so more and larger experiments can be ran."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e9854f",
   "metadata": {},
   "source": [
    "# Attempt to increase compute\n",
    "\n",
    "Seeing as I deleted my AWS account and cannot access it, I turned to runpod.io for access to GPUs. I also switched to WSL for development on my Windows 11 machine, and plan to run tests locally and deploy training runs on the GPUs. Another difficulty is setting up a rational workflow between local and deployment environments. I am able to ssh into the runpod machines, but cannot easily connect to VSCodes workspace, so I must switch to production runs using .py files rather than .ipynb.\n",
    "\n",
    "Setting up a virtual environment on runpod was also a pain. I ended up needing to use the following:\n",
    "\n",
    "sudo apt update\n",
    "sudo apt install python3.11 python3.11-venv python3.11-distutils -y\n",
    "python3.11 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "python -m pip install --upgrade pip\n",
    "\n",
    "However, the requirements.txt file is not working. Everything needs to be install manually. Not a big deal as these are small fun experiments."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
